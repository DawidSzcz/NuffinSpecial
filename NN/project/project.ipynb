{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: pylab import has clobbered these variables: ['gamma']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Elemwise{exp,no_inplace}(<TensorType(float64, vector)>)]\n",
      "Looping 1000 times took 3.517826 seconds\n",
      "Result is [ 1.23178032  1.61879341  1.52278065 ...,  2.20771815  2.29967753\n",
      "  1.62323285]\n",
      "Used the cpu\n"
     ]
    }
   ],
   "source": [
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], T.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in xrange(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# These are taken from https://github.com/mila-udem/blocks\n",
    "# \n",
    "\n",
    "class Constant():\n",
    "    \"\"\"Initialize parameters to a constant.\n",
    "    The constant may be a scalar or a :class:`~numpy.ndarray` of any shape\n",
    "    that is broadcastable with the requested parameter arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    constant : :class:`~numpy.ndarray`\n",
    "        The initialization value to use. Must be a scalar or an ndarray (or\n",
    "        compatible object, such as a nested list) that has a shape that is\n",
    "        broadcastable with any shape requested by `initialize`.\n",
    "    \"\"\"\n",
    "    def __init__(self, constant):\n",
    "        self._constant = numpy.asarray(constant)\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        dest = numpy.empty(shape, dtype=np.float64)\n",
    "        dest[...] = self._constant\n",
    "        return dest\n",
    "\n",
    "\n",
    "class IsotropicGaussian():\n",
    "    \"\"\"Initialize parameters from an isotropic Gaussian distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    std : float, optional\n",
    "        The standard deviation of the Gaussian distribution. Defaults to 1.\n",
    "    mean : float, optional\n",
    "        The mean of the Gaussian distribution. Defaults to 0\n",
    "    Notes\n",
    "    -----\n",
    "    Be careful: the standard deviation goes first and the mean goes\n",
    "    second!\n",
    "    \"\"\"\n",
    "    def __init__(self, std=1, mean=0):\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        m = rng.normal(self._mean, self._std, size=shape)\n",
    "        return m.astype(np.float64)\n",
    "\n",
    "\n",
    "class Uniform():\n",
    "    \"\"\"Initialize parameters from a uniform distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean : float, optional\n",
    "        The mean of the uniform distribution (i.e. the center of mass for\n",
    "        the density function); Defaults to 0.\n",
    "    width : float, optional\n",
    "        One way of specifying the range of the uniform distribution. The\n",
    "        support will be [mean - width/2, mean + width/2]. **Exactly one**\n",
    "        of `width` or `std` must be specified.\n",
    "    std : float, optional\n",
    "        An alternative method of specifying the range of the uniform\n",
    "        distribution. Chooses the width of the uniform such that random\n",
    "        variates will have a desired standard deviation. **Exactly one** of\n",
    "        `width` or `std` must be specified.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0., width=None, std=None):\n",
    "        if (width is not None) == (std is not None):\n",
    "            raise ValueError(\"must specify width or std, \"\n",
    "                             \"but not both\")\n",
    "        if std is not None:\n",
    "            # Variance of a uniform is 1/12 * width^2\n",
    "            self._width = numpy.sqrt(12) * std\n",
    "        else:\n",
    "            self._width = width\n",
    "        self._mean = mean\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        w = self._width / 2\n",
    "        print 'u', shape\n",
    "        m = rng.uniform(self._mean - w, self._mean + w, size=shape)\n",
    "        return m.astype(np.float64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self, rng=None, name=\"\"):\n",
    "        self.name = name\n",
    "        if rng is None:\n",
    "            rng = numpy.random\n",
    "        self.rng = rng\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "    @property\n",
    "    def parameter_names(self):\n",
    "        return []\n",
    "    \n",
    "    def get_gradients(self, dLdY, fprop_context):\n",
    "        return []\n",
    "    \n",
    "    def update(self, foo, alpha):\n",
    "        return []\n",
    "    def cost(self):\n",
    "        return 0;\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class AffineLayer(Layer):\n",
    "    def __init__(self, num_in, num_out, gamma = None, n = \"\", weight_init=None, bias_init=None, **kwargs):\n",
    "        super(AffineLayer, self).__init__(name= n, **kwargs)\n",
    "        if weight_init is None:\n",
    "            weight_init = Uniform(width = 0.1)\n",
    "        if bias_init is None:\n",
    "            bias_init = Constant(0.0)\n",
    "        if gamma is None:\n",
    "            self.gamma = theano.shared(0.1)\n",
    "        else:\n",
    "            self.gamma = theano.shared(gamma, name = self.name + \" gamma\")\n",
    "        self.W = theano.shared(weight_init.generate(self.rng, (num_in, num_out)),name=self.name +\" weight\")\n",
    "        self.b = theano.shared(bias_init.generate(self.rng, (num_out)), name=self.name +\" bias\")\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return [self.W, self.b]\n",
    "    @property\n",
    "    def parametersValues(self):\n",
    "        return [self.W.get_value(), self.b.get_value()]\n",
    "    @property\n",
    "    def parameter_names(self):\n",
    "        return ['W','b']\n",
    "    \n",
    "    def build(self, X):\n",
    "        print self.name+ \" \",X.shape \n",
    "        return X.dot(self.W) + self.b\n",
    "    def cost(self):\n",
    "        return  (self.W ** 2).sum() * self.gamma\n",
    "    def update(self, foo, alpha):\n",
    "        gw, gb = T.grad(foo, self.parameters)\n",
    "        return  [(self.W, self.W -alpha * gw), (self.b, self.b - alpha * gb)]\n",
    "    \n",
    "class LogRegLayer(Layer):\n",
    "    def __init__(self, n = \"\", **kwargs):\n",
    "        super(LogRegLayer, self).__init__(name = n, **kwargs)\n",
    "    def build(self, X):\n",
    "        return T.nnet.sigmoid(X)\n",
    "\n",
    "\n",
    "class TanhLayer(Layer, ):\n",
    "    def __init__(self, n = \"\", **kwargs):\n",
    "        super(TanhLayer, self).__init__(name = n, **kwargs)\n",
    "    def build(self, X):\n",
    "        return T.tanh(X)\n",
    "\n",
    "    \n",
    "class ReLULayer(Layer):\n",
    "    def __init__(self, n = \"\", **kwargs):\n",
    "        super(ReLULayer, self).__init__(name = n, **kwargs)\n",
    "    \n",
    "    def build(self, X):\n",
    "        return T.nnet.relu(X)\n",
    "\n",
    "    \n",
    "class SoftMaxLayer(Layer):\n",
    "    def __init__(self, n = \"\", **kwargs):\n",
    "        super(SoftMaxLayer, self).__init__(name = n, **kwargs)\n",
    "    \n",
    "    def build(self, X):\n",
    "        return T.nnet.softmax(X)\n",
    "    \n",
    "class FeedForwardNet(object):\n",
    "    def __init__(self, layers=None, alpha=0.1):\n",
    "        if layers is None:\n",
    "            layers = []\n",
    "        self.layers = layers\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            params += layer.parameters\n",
    "        return params\n",
    "    \n",
    "    @parameters.setter\n",
    "    def parameters(self, values):\n",
    "        for ownP, newP in zip(self.parameters, values):\n",
    "            ownP[...] = newP\n",
    "    \n",
    "    @property\n",
    "    def parameter_names(self):\n",
    "        param_names = []\n",
    "        for layer in self.layers:\n",
    "            param_names += layer.parameter_names\n",
    "        return param_names\n",
    "    \n",
    "    def build(self):\n",
    "        x = T.matrix(\"x\")\n",
    "        y = T.vector(\"y\", dtype='int64')\n",
    "        cost = 0\n",
    "        paramUpdates = []\n",
    "        \n",
    "        X = x\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            X = layer.build(X)\n",
    "            cost += layer.cost()\n",
    "        \n",
    "        pred = np.argmax(X, 1)\n",
    "        self.costFoo = T.nnet.categorical_crossentropy(X, y).mean() + cost\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            paramUpdates += layer.update(self.costFoo, self.alpha)\n",
    "         \n",
    "        self.train = theano.function(inputs=[x,y], \n",
    "                                    outputs=[pred, self.costFoo],\n",
    "                                    updates=paramUpdates)\n",
    "        self.predict  = theano.function(inputs=[x], \n",
    "                                    outputs=pred)\n",
    "        \n",
    "    \n",
    "    @property\n",
    "    def trainFunction(self):\n",
    "        return self.train\n",
    "    \n",
    "    @property\n",
    "    def predictFunction(self):\n",
    "        return self.predict\n",
    "    @property\n",
    "    def costFunction(self):\n",
    "        return self.costFoo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def xent(x , y):\n",
    "        return  -y * T.log(x) - (1-y) * T.log(1-x)\n",
    "    \n",
    "    def costF(x, w):\n",
    "        return x.mean() + 0.01 * (w ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fuel.datasets.mnist import MNIST\n",
    "from fuel.transformers import ScaleAndShift, Cast, Flatten, Mapping\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import SequentialScheme, ShuffledScheme\n",
    "\n",
    "MNIST.default_transformers = (\n",
    "    (ScaleAndShift, [2.0 / 255.0, -1], {'which_sources': 'features'}),\n",
    "    (Cast, [np.float32], {'which_sources': 'features'}), \n",
    "    (Flatten, [], {'which_sources': 'features'}),\n",
    "    (Mapping, [lambda batch: (b.T for b in batch)], {}) )\n",
    "\n",
    "mnist_train = MNIST((\"train\",), subset=slice(None,50000))\n",
    "#this stream will shuffle the MNIST set and return us batches of 100 examples\n",
    "mnist_train_stream = DataStream.default_stream(\n",
    "    mnist_train,\n",
    "    iteration_scheme=ShuffledScheme(mnist_train.num_examples, 100))\n",
    "\n",
    "                         \n",
    "mnist_validation = MNIST((\"train\",), subset=slice(50000, None))\n",
    "\n",
    "# We will use larger portions for testing and validation\n",
    "# as these dont do a backward pass and reauire less RAM.\n",
    "mnist_validation_stream = DataStream.default_stream(\n",
    "    mnist_validation, iteration_scheme=SequentialScheme(mnist_validation.num_examples, 250))\n",
    "mnist_test = MNIST((\"test\",))\n",
    "mnist_test_stream = DataStream.default_stream(\n",
    "    mnist_test, iteration_scheme=SequentialScheme(mnist_test.num_examples, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fuel.datasets.cifar10 import CIFAR10\n",
    "from fuel.transformers import ScaleAndShift, Cast, Flatten, Mapping\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import SequentialScheme, ShuffledScheme\n",
    "\n",
    "CIFAR10.default_transformers = (\n",
    "    (ScaleAndShift, [2.0 / 255.0, -1], {'which_sources': 'features'}),\n",
    "    (Cast, [np.float32], {'which_sources': 'features'}), \n",
    "    (Flatten, [], {'which_sources': 'features'}),\n",
    "    (Mapping, [lambda batch: (b.T for b in batch)], {}) )\n",
    "\n",
    "cifar10_train = CIFAR10((\"train1\",), subset=slice(None,10000))\n",
    "#this stream will shuffle the MNIST set and return us batches of 100 examples\n",
    "cifar10_train_stream = DataStream.default_stream(\n",
    "    cifar10_train,\n",
    "    iteration_scheme=ShuffledScheme(cifar10_train.num_examples, 100))\n",
    "                                               \n",
    "cifar10_validation = CIFAR10((\"train2\",), subset=slice(None,10000))\n",
    "\n",
    "# We will use larger portions for testing and validation\n",
    "# as these dont do a backward pass and reauire less RAM.\n",
    "cifar10_validation_stream = DataStream.default_stream(\n",
    "    cifar10_validation, iteration_scheme=SequentialScheme(cifar10_validation.num_examples, 250))\n",
    "cifar10_test = CIFAR10((\"test\",))\n",
    "cifar10_test_stream = DataStream.default_stream(\n",
    "    cifar10_test, iteration_scheme=SequentialScheme(cifar10_test.num_examples, 250))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The streams return batches containing (u'features', u'targets')\n",
      "Each trainin batch consits of a tuple containing:\n",
      " - an array of size (784, 100) containing float32\n",
      " - an array of size (1, 100) containing uint8\n",
      "Validation/test batches consits of tuples containing:\n",
      " - an array of size (784, 250) containing float32\n",
      " - an array of size (1, 250) containing uint8\n",
      "CIFAR: \n",
      "The streams return batches containing (u'batch1_features', u'batch1_targets')\n",
      "Each trainin batch consits of a tuple containing:\n",
      " - an array of size (3072, 100) containing uint8\n",
      " - an array of size (1, 100) containing uint8\n",
      "Validation/test batches consits of tuples containing:\n",
      " - an array of size (3072, 250) containing uint8\n",
      " - an array of size (1, 250) containing uint8\n"
     ]
    }
   ],
   "source": [
    "print \"The streams return batches containing %s\" % (mnist_train_stream.sources,)\n",
    "\n",
    "print \"Each trainin batch consits of a tuple containing:\"\n",
    "for element in next(mnist_train_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)\n",
    "    \n",
    "print \"Validation/test batches consits of tuples containing:\"\n",
    "for element in next(mnist_test_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)\n",
    "    \n",
    "print \"CIFAR: \"  \n",
    "print \"The streams return batches containing %s\" % (cifar10_train_stream.sources,)\n",
    "\n",
    "print \"Each trainin batch consits of a tuple containing:\"\n",
    "for element in next(cifar10_train_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)\n",
    "    \n",
    "print \"Validation/test batches consits of tuples containing:\"\n",
    "for element in next(cifar10_test_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "#print iris\n",
    "\n",
    "feats = 4\n",
    "alpha = 0.01\n",
    "pop_num = 150\n",
    "rng = np.random\n",
    "iris_f = iris['data'][:pop_num,:feats]\n",
    "iris_t = iris['target'][:pop_num]\n",
    "iris = hstack(([[x] for x in iris_t], iris_f))\n",
    "\n",
    "rng.shuffle(iris)\n",
    "\n",
    "#print iris\n",
    "\n",
    "iris_train_f = iris[:2*pop_num/3,1:]\n",
    "iris_train_t = np.array(iris[:2*pop_num/3, 0], dtype='uint8')\n",
    "iris_test_f = iris[2*pop_num/3:,1:]\n",
    "iris_test_t = np.array(iris[2*pop_num/3:, 0], dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_er(net, stream):\n",
    "    num_errs = 0.0\n",
    "    num_examples = 0\n",
    "    for X, Y in stream.get_epoch_iterator():\n",
    "        predictions = net.predictFunction(X.T)\n",
    "        num_errs += (predictions != Y).sum()\n",
    "        num_examples += X.shape[1]\n",
    "    return num_errs/num_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u (3072, 500)\n",
      "u (500, 200)\n",
      "u (200, 10)\n",
      "fA  Shape.0\n",
      "sA  Shape.0\n",
      "tA  Shape.0\n",
      "Start\n",
      "gamma:  0.0001\n",
      "alpha:  0.001\n",
      "2.41911071388 0.12\n",
      "After epoch:  0 0.8608\n",
      "2.43397561275 0.1\n",
      "After epoch:  1 0.8284\n",
      "2.37450479821 0.18\n",
      "After epoch:  2 0.8026\n",
      "2.33624778318 0.28\n",
      "After epoch:  3 0.7801\n",
      "2.37369939638 0.21\n",
      "After epoch:  4 0.7767\n",
      "2.32854698923 0.2\n",
      "After epoch:  5 0.7629\n",
      "2.26002768524 0.29\n",
      "After epoch:  6 0.761\n",
      "2.27938271596 0.29\n",
      "After epoch:  7 0.748\n",
      "2.2570439163 0.22\n",
      "After epoch:  8 0.7414\n",
      "2.25343617196 0.29\n",
      "After epoch:  9 0.7411\n",
      "2.21191922617 0.25\n",
      "After epoch:  10 0.7365\n",
      "2.2142542755 0.34\n",
      "After epoch:  11 0.7279\n",
      "2.17168345324 0.34\n",
      "After epoch:  12 0.7286\n",
      "2.21526886242 0.24\n",
      "After epoch:  13 0.7203\n",
      "2.15006709184 0.29\n",
      "After epoch:  14 0.7157\n",
      "2.17555201471 0.24\n",
      "After epoch:  15"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-281-a4d1d4325547>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;32mprint\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpr\u001b[0m  \u001b[1;33m==\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[1;32mprint\u001b[0m \u001b[1;34m\"After epoch: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_er\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcifar10_validation_stream\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0me\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-272-da7b59515ed1>\u001b[0m in \u001b[0;36mcompute_er\u001b[1;34m(net, stream)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mnum_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_epoch_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mnum_errs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mnum_examples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kazek/anaconda3/envs/p2.7/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import theano.printing as TP\n",
    "from IPython.display import SVG\n",
    "def svgdotprint(g):\n",
    "    return SVG(theano.printing.pydotprint(g, return_image=True, format='svg'))\n",
    "import time\n",
    "\n",
    "\n",
    "feats = 3072\n",
    "hidden1 = 500\n",
    "hidden2 = 200\n",
    "outs = 10\n",
    "gamma = 0.0001\n",
    "alpha = 0.001\n",
    "num_epochs  = 100\n",
    "\n",
    "net = FeedForwardNet([AffineLayer(feats, hidden, gamma, \"fA\"), \n",
    "                      TanhLayer(\"fTanh\"),\n",
    "                      AffineLayer(hidden1, hidden2, gamma, \"sA\"), \n",
    "                      TanhLayer(\"fTanh\"),\n",
    "                      AffineLayer(hidden2, outs, gamma, \"tA\"), \n",
    "                      SoftMaxLayer(\"fSoftMax\")], alpha)\n",
    "net.build()\n",
    "print \"Start\"\n",
    "print \"gamma: \", gamma\n",
    "print \"alpha: \", alpha\n",
    "i = 0\n",
    "e = 0\n",
    "while e < num_epochs:\n",
    "    for X, Y in cifar10_train_stream.get_epoch_iterator():\n",
    "        pr ,c = net.trainFunction(X.T, Y.ravel())\n",
    "        i+=1\n",
    "        if i % 100 == 0:\n",
    "            print c, (pr  == Y).mean()\n",
    "    \n",
    "    print \"After epoch: \", e, compute_er(net, cifar10_validation_stream)\n",
    "    e+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u (784, 500)\n",
      "u (500, 200)\n",
      "u (200, 10)\n",
      "fA  Shape.0\n",
      "sA  Shape.0\n",
      "tA  Shape.0\n",
      "Start\n",
      "After epoch:  0 0.0828\n",
      "After epoch:  1 0.0602\n",
      "After epoch:  2 0.0525\n",
      "After epoch:  3 0.0425\n",
      "After epoch:  4 0.0397\n",
      "After epoch:  5 0.0406\n",
      "After epoch:  6 0.0331\n",
      "After epoch:  7 0.0484\n",
      "After epoch:  8 0.0304\n",
      "After epoch:  9 0.0297\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-277-b5972cc716aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[0me\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmnist_train_stream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_epoch_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m         \u001b[0mpr\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m         \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m#if i % 100 == 0:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kazek/anaconda3/envs/p2.7/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feats = 784\n",
    "hidden1 = 500\n",
    "hidden2 = 200\n",
    "outs = 10\n",
    "gamma = 0.001\n",
    "alpha = 0.1\n",
    "num_epochs  = 100\n",
    "\n",
    "net = FeedForwardNet([AffineLayer(feats, hidden, gamma, \"fA\"), \n",
    "                      TanhLayer(\"fTanh\"),\n",
    "                      AffineLayer(hidden1, hidden2, gamma, \"sA\"), \n",
    "                      TanhLayer(\"fTanh\"),\n",
    "                      AffineLayer(hidden2, outs, gamma, \"tA\"), \n",
    "                      SoftMaxLayer(\"fSoftMax\")], alpha)\n",
    "net.build()\n",
    "print \"Start\"\n",
    "i = 0\n",
    "e = 0\n",
    "while e < num_epochs:\n",
    "    for X, Y in mnist_train_stream.get_epoch_iterator():\n",
    "        pr ,c = net.trainFunction(X.T, Y.ravel())\n",
    "        i+=1\n",
    "        #if i % 100 == 0:\n",
    "            #print c, (pr  == Y).mean()\n",
    "    \n",
    "    print \"After epoch: \", e, compute_er(net, mnist_validation_stream)\n",
    "    e+=1\n",
    "\n",
    "    \n",
    "for X, Y in mnist_validation_stream.get_epoch_iterator():\n",
    "    predictions = net.predictFunction(X.T)\n",
    "    num_errs += (predictions != Y).sum()\n",
    "    num_examples += X.shape[1]\n",
    "    k+=1\n",
    "print num_errs, num_examples, k, num_errs/num_examples\n",
    "#print (iris_test_t  == net.predictFunction(iris_test_f)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u (4, 500)\n",
      "u (500, 3)\n",
      "fA  Shape.0\n",
      "sA  Shape.0\n",
      "[1 1 1 2 0 1 2 1 2 1 0 0 0 2 0 1 1 0 2 0 0 0 2 2 2 0 1 1 2 1 2 1 1 2 1 1 2\n",
      " 1 2 0 2 2 2 1 2 2 2 1 1 1 0 2 2 2 1 0 0 1 2 0 0 1 0 2 0 0 1 2 0 1 0 2 1 2\n",
      " 2 2 0 0 0 2 1 0 0 2 2 2 0 2 1 0 2 0 1 2 2 0 2 1 0 1]\n",
      "1.09631703364 0.31\n",
      "0.317733354127 0.86\n",
      "0.197407528746 0.92\n",
      "0.121202746755 0.99\n",
      "0.105924980376 0.99\n",
      "0.0999223132933 0.98\n",
      "0.0966232818172 0.99\n",
      "0.0943991315485 0.99\n",
      "0.0927725225664 0.99\n",
      "0.0915170037309 0.99\n",
      "0.0905069747664 0.99\n",
      "0.0896673708137 0.99\n",
      "0.0889508866144 0.99\n",
      "0.0883264893901 0.99\n",
      "0.0877731482594 0.99\n",
      "0.0872762028404 0.99\n",
      "0.0868251649859 0.99\n",
      "0.0864123427317 0.99\n",
      "0.0860319563461 0.99\n",
      "0.0856795586053 0.99\n",
      "0.0853516479336 0.99\n",
      "0.0850454062796 0.99\n",
      "0.0847585190085 0.99\n",
      "0.0844890494927 0.99\n",
      "0.0842353506364 0.99\n",
      "0.0839960016216 0.99\n",
      "0.0837697620477 0.99\n",
      "0.083555538178 0.99\n",
      "0.0833523576834 0.99\n",
      "0.0831593504002 0.99\n",
      "0.0829757333839 0.99\n",
      "0.082800799064 0.99\n",
      "0.0826339056679 0.99\n",
      "0.0824744693341 0.99\n",
      "0.0823219575082 0.99\n",
      "0.0821758833383 0.99\n",
      "0.0820358008677 0.99\n",
      "0.0819013008786 0.98\n",
      "0.0817720072788 0.98\n",
      "0.0816475739462 0.98\n",
      "0.081527681963 0.98\n",
      "0.0814120371814 0.98\n",
      "0.0813003680713 0.98\n",
      "0.0811924238075 0.98\n",
      "0.0810879725595 0.98\n",
      "0.0809867999517 0.98\n",
      "0.0808887076709 0.98\n",
      "0.0807935121971 0.98\n",
      "0.0807010436436 0.98\n",
      "0.0806111446907 0.98\n",
      "0.0805236696055 0.98\n",
      "0.0804384833364 0.98\n",
      "0.0803554606784 0.98\n",
      "0.0802744855016 0.98\n",
      "0.0801954500395 0.98\n",
      "0.0801182542324 0.98\n",
      "0.0800428051212 0.98\n",
      "0.0799690162903 0.98\n",
      "0.0798968073534 0.98\n",
      "0.0798261034812 0.98\n",
      "0.0797568349669 0.98\n",
      "0.0796889368269 0.98\n",
      "0.079622348434 0.98\n",
      "0.0795570131807 0.98\n",
      "0.0794928781697 0.98\n",
      "0.0794298939299 0.98\n",
      "0.0793680141559 0.98\n",
      "0.079307195468 0.98\n",
      "0.0792473971928 0.98\n",
      "0.0791885811604 0.98\n",
      "0.0791307115195 0.98\n",
      "0.0790737545661 0.98\n",
      "0.0790176785867 0.98\n",
      "0.0789624537139 0.98\n",
      "0.0789080517935 0.98\n",
      "0.0788544462621 0.98\n",
      "0.0788016120344 0.98\n",
      "0.0787495253995 0.98\n",
      "0.0786981639249 0.98\n",
      "0.0786475063683 0.98\n",
      "0.0785975325965 0.98\n",
      "0.0785482235101 0.98\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-266-24be9bd4f835>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0miris_train_t\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mpr\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miris_train_f\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miris_train_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mprint\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpr\u001b[0m  \u001b[1;33m==\u001b[0m \u001b[0miris_train_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/kazek/anaconda3/envs/p2.7/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import theano.printing as TP\n",
    "from IPython.display import SVG\n",
    "def svgdotprint(g):\n",
    "    return SVG(theano.printing.pydotprint(g, return_image=True, format='svg'))\n",
    "\n",
    "\n",
    "\n",
    "feats = 4\n",
    "hidden = 500\n",
    "outs = 3\n",
    "gamma = 0.001\n",
    "alpha = 0.1\n",
    "\n",
    "net = FeedForwardNet([AffineLayer(feats, hidden, gamma, \"fA\"), \n",
    "          TanhLayer(\"fTanh\"),\n",
    "          AffineLayer(hidden, outs, gamma, \"sA\"), \n",
    "          SoftMaxLayer(\"fSoftMax\")], alpha)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#theano.printing.pydotprint(costFoo, outfile=\"symbolic_graph_unopt.png\", var_with_name_simple=True)  \n",
    "\n",
    "\n",
    "net.build()\n",
    "\n",
    "print iris_train_t\n",
    "for i in range(10000):\n",
    "    pr ,c = net.trainFunction(iris_train_f, iris_train_t)\n",
    "    if i % 100 == 0:\n",
    "        print c, (pr  == iris_train_t).mean()\n",
    "\n",
    "print (pr  == iris_train_t).mean()\n",
    "print pr\n",
    "\n",
    "figure()\n",
    "subplot(2,1,1)\n",
    "scatter(iris_test_f[:,0], iris_test_f[:,1], c=iris_test_t.ravel(), cmap='prism')\n",
    "subplot(2,1,2)\n",
    "scatter(iris_test_f[:,0], iris_test_f[:,1], c=net.predicFunction(iris_test_f), cmap='prism')\n",
    "print (iris_test_t  == net.predictFunction(iris_test_f)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'TensorVariable' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-7f6cd228eadb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mp_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# Probability that target = 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp_1\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0.5\u001b[0m                    \u001b[1;31m# The prediction thresholded\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcostF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m# The cost to minimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mgw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m             \u001b[1;31m# Compute the gradient of the cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                                           \u001b[1;31m# (we shall return to this in a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'TensorVariable' object is not callable"
     ]
    }
   ],
   "source": [
    "#print iris_test_t\n",
    "\n",
    "w = theano.shared(rng.randn(feats)*0.01, name=\"w\")\n",
    "#print w.get_value()\n",
    "b = theano.shared(0., name=\"b\")\n",
    "#print b.get_value()\n",
    "x = T.matrix(\"x\")\n",
    "y = T.vector(\"y\")\n",
    "\n",
    "p_1 = T.nnet.sigmoid(T.dot(x, w) + b)   # Probability that target = 1\n",
    "prediction = p_1 > 0.5                    # The prediction thresholded\n",
    "c = costF(xent(p_1, y), w)# The cost to minimize\n",
    "gw, gb = T.grad(c, [w, b])             # Compute the gradient of the cost\n",
    "                                          # (we shall return to this in a\n",
    "                                          # following section of this tutorial)\n",
    "\n",
    "train = theano.function(\n",
    "          inputs=[x,y],\n",
    "          outputs=[prediction, c],\n",
    "          updates=((w, w - alpha * gw), (b, b - alpha * gb)))\n",
    "predict = theano.function(inputs=[x], outputs=prediction)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    p, c =train(iris_train_f, iris_train_t)\n",
    "    #print p, c, x.mean()\n",
    "    \n",
    "print (predict(iris_test_f) == iris_test_t).mean()\n",
    "\n",
    "\n",
    "#foo = theano.function(inputs=[iris_train_f], outputs=[f])\n",
    "\n",
    "#print iris_test_t\n",
    "figure()\n",
    "subplot(2,1,1)\n",
    "scatter(iris_test_f[:,0], iris_test_f[:,1], c=iris_test_t.ravel(), cmap='spring')\n",
    "subplot(2,1,2)\n",
    "scatter(iris_test_f[:,0], iris_test_f[:,1], c=predict(iris_test_f).ravel(), cmap='spring')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u (4, 500)\n",
      "u (500, 1)\n",
      "The output file is available at symbolic_graph_unopt.png\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f6a078f8590>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6a083d3490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import theano.printing as TP\n",
    "from IPython.display import SVG\n",
    "def svgdotprint(g):\n",
    "    return SVG(theano.printing.pydotprint(g, return_image=True, format='svg'))\n",
    "\n",
    "\n",
    "\n",
    "x = T.matrix(\"x\")\n",
    "y = T.vector(\"y\")\n",
    "feats = 4\n",
    "hidden = 500\n",
    "outs = 1\n",
    "gamma = 0.1\n",
    "alpha = 0.1\n",
    "\n",
    "fAL = AffineLayer(feats, hidden, gamma, \"fA\")\n",
    "tL = TanhLayer()\n",
    "sAL = AffineLayer(hidden, outs, gamma, \"sA\")\n",
    "lL = LogRegLayer()\n",
    "\n",
    "fa = fAL.build(x)\n",
    "t = tL.build(fa)\n",
    "sa = sAL.build(t)\n",
    "out = lL.build(sa)\n",
    "pred = out > 0.5\n",
    "c = xent(out.ravel(), y).mean() + fAL.cost() + sAL.cost()\n",
    "\n",
    "theano.printing.pydotprint(out, outfile=\"symbolic_graph_unopt.png\", var_with_name_simple=True)  \n",
    "fgw, fgb = T.grad(c, fAL.parameters)\n",
    "sgw, sgb = T.grad(c, sAL.parameters)\n",
    "\n",
    "train = theano.function(inputs=[x,y], \n",
    "                        outputs=[pred, c], \n",
    "                        updates=(fAL.update(c, alpha) + sAL.update(c, alpha)))\n",
    "predict  = theano.function(inputs=[x], \n",
    "                        outputs=[pred])\n",
    "\n",
    "for i in range(100):\n",
    "    pr, cost = train(iris_train_f, iris_train_t)\n",
    "\n",
    "print (pr.ravel() == iris_train_t).mean()\n",
    "\n",
    "\n",
    "figure()\n",
    "subplot(2,1,1)\n",
    "scatter(iris_test_f[:,0], iris_test_f[:,1], c=iris_test_t.ravel(), cmap='spring')\n",
    "subplot(2,1,2)\n",
    "scatter(iris_test_f[:,0], iris_test_f[:,1], c=predict(iris_test_f), cmap='spring')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 2, 3]"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = np.array([[12, 13], [1, 3]])\n",
    "y1 = [1, 2]\n",
    "print x.shape\n",
    "y = T.vector()\n",
    "x = T.matrix()\n",
    "f = theano.function(inputs=[x, y], outputs=x+y)\n",
    "f(x1, y1)\n",
    "\n",
    "\n",
    "x2 = [1,2]\n",
    "y2 = [2,3]\n",
    "x2 + y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
